{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: training_pipeline.html\n",
    "title: 'Define: Training Pipeline'\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577d8b2a-910d-4a34-b364-e037ec84ed29",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a95d46-5753-42d0-945f-c1905385b2c8",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011e6365-a5e7-41fd-9a9d-4c836a7a71d6",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: \"Exported source\"\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from colorama import Fore, Style\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from advanced_autoencoders.config import ConfigMaeLarge, ConfigVQVAE\n",
    "from advanced_autoencoders.dataset import MyImageDataset\n",
    "from advanced_autoencoders.trainers import (\n",
    "    PlModelMAE,\n",
    "    PlModelVQVAE,\n",
    "    get_model_checkpoint_callback,\n",
    "    get_trainer_mae,\n",
    "    get_trainer_vq,\n",
    ")\n",
    "from advanced_autoencoders.utils import (\n",
    "    get_train_transforms,\n",
    "    make_images_dataframe,\n",
    "    seed_everything,\n",
    ")\n",
    "\n",
    "r_ = Fore.RED\n",
    "b_ = Fore.BLUE\n",
    "c_ = Fore.CYAN\n",
    "g_ = Fore.GREEN\n",
    "y_ = Fore.YELLOW\n",
    "m_ = Fore.MAGENTA\n",
    "sr_ = Style.RESET_ALL\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64507607-652b-455f-be6a-ffee294330ca",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/advanced_autoencoders/blob/main/advanced_autoencoders/training_pipelines.py#L40){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### make_train_test_split\n",
       "\n",
       ">      make_train_test_split (df:pandas.core.frame.DataFrame, cnfg)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/advanced_autoencoders/blob/main/advanced_autoencoders/training_pipelines.py#L40){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### make_train_test_split\n",
       "\n",
       ">      make_train_test_split (df:pandas.core.frame.DataFrame, cnfg)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(make_train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2705ad39-2fa4-4d19-b16f-694fc89450a7",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: \"Exported source\"\n",
    "def make_train_test_split(df: pd.DataFrame, cnfg):\n",
    "    df_train, df_val = train_test_split(df, test_size=cnfg.size_val, random_state=42)\n",
    "\n",
    "    return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/advanced_autoencoders/blob/main/advanced_autoencoders/training_pipelines.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_reconstruction_sample\n",
       "\n",
       ">      get_reconstruction_sample (cnfg, df)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/advanced_autoencoders/blob/main/advanced_autoencoders/training_pipelines.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_reconstruction_sample\n",
       "\n",
       ">      get_reconstruction_sample (cnfg, df)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_reconstruction_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef0cc2f-f12e-44d8-af40-c69a7ef21ce2",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: \"Exported source\"\n",
    "def get_reconstruction_sample(cnfg, df):\n",
    "    val_reconstruction_dataset = MyImageDataset(\n",
    "        df, augmentations=get_train_transforms(cnfg)\n",
    "    )\n",
    "    val_dl_rec = DataLoader(val_reconstruction_dataset, batch_size=4, shuffle=False)\n",
    "    for test_sample in val_dl_rec:\n",
    "        break\n",
    "    test_sample = test_sample.cuda(f\"cuda:{cnfg.gpus[0]}\")\n",
    "\n",
    "    return test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/advanced_autoencoders/blob/main/advanced_autoencoders/training_pipelines.py#L58){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### train_pipeline_mae\n",
       "\n",
       ">      train_pipeline_mae ()"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/advanced_autoencoders/blob/main/advanced_autoencoders/training_pipelines.py#L58){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### train_pipeline_mae\n",
       "\n",
       ">      train_pipeline_mae ()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(train_pipeline_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be5d7fa-0afc-4e01-83df-0d542cca4425",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: \"Exported source\"\n",
    "def train_pipeline_mae():\n",
    "    CONFIG = ConfigMaeLarge()\n",
    "    seed_everything(seed=CONFIG.seed)\n",
    "    df_all = make_images_dataframe(CONFIG)\n",
    "    print(f\"Making Image DF from DIR DONE! TOTAL IMAGES:{df_all.shape[0]}\")\n",
    "    df_train, df_val = make_train_test_split(df_all, CONFIG)\n",
    "    print(\n",
    "        f\"TRAIN VAL SPLIT DONE! TOTAL IMAGES TRAIN:{df_train.shape[0]}, VAL:{df_val.shape[0]}\"\n",
    "    )\n",
    "    test_sample = get_reconstruction_sample(CONFIG, df_val)\n",
    "    checkpoint_callback = get_model_checkpoint_callback(CONFIG)\n",
    "    trainer = get_trainer_mae(CONFIG, checkpoint_callback)\n",
    "    pl_model = PlModelMAE(CONFIG, df_train, df_val, test_sample)\n",
    "\n",
    "    trainer.fit(pl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba670555-a735-4e29-8d6a-215331bb88b6",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/advanced_autoencoders/blob/main/advanced_autoencoders/training_pipelines.py#L75){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### train_pipeline_vqvae\n",
       "\n",
       ">      train_pipeline_vqvae ()"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/advanced_autoencoders/blob/main/advanced_autoencoders/training_pipelines.py#L75){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### train_pipeline_vqvae\n",
       "\n",
       ">      train_pipeline_vqvae ()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(train_pipeline_vqvae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae312377-a55a-433e-a65a-89de38bbacc1",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: \"Exported source\"\n",
    "def train_pipeline_vqvae():\n",
    "    CONFIG = ConfigVQVAE()\n",
    "    seed_everything(seed=CONFIG.seed)\n",
    "    df_all = make_images_dataframe(CONFIG)\n",
    "    print(f\"Making Image DF from DIR DONE! TOTAL IMAGES:{df_all.shape[0]}\")\n",
    "    df_train, df_val = make_train_test_split(df_all, CONFIG)\n",
    "    print(\n",
    "        f\"TRAIN VAL SPLIT DONE! TOTAL IMAGES TRAIN:{df_train.shape[0]}, VAL:{df_val.shape[0]}\"\n",
    "    )\n",
    "    test_sample = get_reconstruction_sample(CONFIG, df_val)\n",
    "    checkpoint_callback = get_model_checkpoint_callback(CONFIG)\n",
    "    trainer = get_trainer_vq(CONFIG, checkpoint_callback)\n",
    "    pl_model = PlModelVQVAE(CONFIG, df_train, df_val, test_sample)\n",
    "\n",
    "    trainer.fit(pl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5962a1-694c-4da2-95d3-b29279b5dbb8",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced3ea57-129d-4173-8db6-1ff30c6a0f4b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
