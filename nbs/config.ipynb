{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc8fa2bc-9c38-4c7d-8499-f37f14704970",
   "metadata": {},
   "source": [
    "# Configs for ViTMAE and VQ-MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd0c05-b820-4aa5-a09c-1b34a5c75b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459e3558-88b0-4e3e-ab49-b43170f51537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ConfigMaeLarge:\n",
    "    seed = 1000\n",
    "\n",
    "    model_name = \"vitmae_fb_large_v5\"\n",
    "    prev_model_name = None\n",
    "\n",
    "    img_size = 256\n",
    "    in_chans = 3\n",
    "    lr = 1e-4\n",
    "    bs = 8\n",
    "    epochs = 2\n",
    "    weight_decay = 0.05\n",
    "    betas = (0.9, 0.95)\n",
    "\n",
    "    gpus = [0]\n",
    "    num_gpus = len(gpus)\n",
    "\n",
    "    embd_dim = 256\n",
    "\n",
    "    # Masked AutoEncoder Params\n",
    "    encoder_embedding_dim = embd_dim\n",
    "    depth_enc = 24\n",
    "    num_heads_enc = 16\n",
    "\n",
    "    decoder_embedding_dim = 128\n",
    "    decoder_depth = 8\n",
    "    decoder_num_heads = 16\n",
    "\n",
    "    mlp_ratio = 4.0\n",
    "\n",
    "    patch_size = 8\n",
    "    mask_ratio = 0.75\n",
    "\n",
    "    DATA_DIR = \"../data/\"\n",
    "    IMG_DIR = DATA_DIR + \"cars_dataset/\"\n",
    "    MODELS_DIR = \"../models/\"\n",
    "\n",
    "    TRAINING_LOGS_DIR = f\"../training_logs/{model_name}/\"\n",
    "    CHECKPOINTS_DIR = TRAINING_LOGS_DIR + \"checkpoints/\"\n",
    "\n",
    "    TRAINING_RECON_IMG_DIR = f\"{TRAINING_LOGS_DIR}{model_name}/\"\n",
    "\n",
    "    embedding_name = \"final2\"\n",
    "    EMBEDDINGS_DIR = DATA_DIR + \"embeddings/\"\n",
    "    EMBEDDING_COL_NAMES = [f\"dim_{k}\" for k in range(encoder_embedding_dim)]\n",
    "    EMBEDDING_FILE_PATH = (\n",
    "        f\"{EMBEDDINGS_DIR}{model_name}_{encoder_embedding_dim}_{embedding_name}.csv\"\n",
    "    )\n",
    "\n",
    "    size_val = 0.2  # Size of validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece276c9-0749-4c83-b3e4-99a373397116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7b759-94c7-48db-b1a6-97642eb096a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81398c0-0770-4c63-a648-3ae83d712909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ConfigVQVAE:\n",
    "    seed = 1000\n",
    "\n",
    "    DATA_DIR = \"../data/\"\n",
    "    IMG_DIR = DATA_DIR + \"cars_dataset/\"\n",
    "    MODELS_DIR = \"../models/\"\n",
    "\n",
    "    img_size = 256\n",
    "\n",
    "    gpus = [0]\n",
    "    num_gpus = len(gpus)\n",
    "\n",
    "    # Training Params\n",
    "    lr = 1e-3\n",
    "    bs = 64\n",
    "    epochs = 100\n",
    "    size_val = 0.2  # Size of validation set\n",
    "\n",
    "    embd_dim = 2048\n",
    "\n",
    "    if embd_dim == 512:\n",
    "        training_name = \"16_16_2_v1\"\n",
    "        num_layers = (\n",
    "            4  # number of downsamples - ex. 256 / (2 ** 3) = (32 x 32 feature map)\n",
    "        )\n",
    "    else:\n",
    "        training_name = \"32_32_2_v2\"\n",
    "        num_layers = (\n",
    "            3  # number of downsamples - ex. 256 / (2 ** 3) = (32 x 32 feature map)\n",
    "        )\n",
    "\n",
    "    # Model Config\n",
    "    model_name = f\"dalle_vq_vae_{training_name}\"\n",
    "\n",
    "    num_tokens = 8192  # number of visual tokens. in the paper, they used 8192, but could be smaller for downsized projects\n",
    "    codebook_dim = 2  # codebook dimension\n",
    "    hidden_dim = 128  # hidden dimension\n",
    "    num_resnet_blocks = 2  # number of resnet blocks\n",
    "    use_vq_commit_loss = True\n",
    "\n",
    "    # Logging\n",
    "    TRAINING_LOGS_DIR = f\"../training_logs/{model_name}/\"\n",
    "    TRAINING_RECON_IMG_DIR = f\"{TRAINING_LOGS_DIR}{model_name}/\"\n",
    "    CHECKPOINTS_DIR = f\"{TRAINING_LOGS_DIR}checkpoints/\"\n",
    "\n",
    "    # Embeddings\n",
    "    EMBEDDINGS_DIR = DATA_DIR + \"embeddings/\"\n",
    "    EMBEDDING_FILE_PATH = f\"{EMBEDDINGS_DIR}{model_name}_{embd_dim}.csv\"\n",
    "    EMBEDDING_COL_NAMES = [f\"dim_{k}\" for k in range(embd_dim)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
